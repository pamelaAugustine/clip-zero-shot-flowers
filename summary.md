The CLIP model performed reasonably well but showed clear limitations due to the small number of categories used for classification. Given that the flower dataset contains multiple images for each flower type, the broad and limited category set made it difficult for the model to assign highly accurate labels. For example, the iris was classified as "A blooming rose" (93.07%), and the snowdrop was misclassified as "A bouquet of tulips" (77.28%), likely due to similarities in shape or color.

However, the model correctly classified the daisy with 97.79% confidence, showing that some flower types closely align with the provided categories. This suggests that when a category matches well with an imageâ€™s features, the model can be highly accurate. To improve overall results, we would need to add more classification categories and use more descriptive prompts tailored to each flower type. Understanding what each flower looks like and refining descriptions would significantly enhance classification accuracy.